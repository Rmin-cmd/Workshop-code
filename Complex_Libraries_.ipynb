{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvKLi4uzXeEx",
        "outputId": "d9d3640c-369d-467b-91e1-193a6f4de692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting complextorch\n",
            "  Downloading complextorch-1.0.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from complextorch) (1.25.2)\n",
            "Installing collected packages: complextorch\n",
            "Successfully installed complextorch-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install complextorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import complextorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import complextorch as comptorch\n",
        "import complextorch.nn as compnn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "BGTF0FORXu-O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
        "train_set = datasets.CIFAR10('./data', train=True, transform=trans, download=True)\n",
        "# train_set = complextorch.CVTensor(train_set, i=torch.zeros_like((train_set)))\n",
        "test_set = datasets.CIFAR10('./data', train=False, transform=trans, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83AuktEXXzam",
        "outputId": "2012ef20-fc79-43da-e14c-a61a9cb4aca6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:18<00:00, 9289254.33it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ComplexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ComplexNet, self).__init__()\n",
        "        self.conv1 = compnn.CVConv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n",
        "        self.relu1 = compnn.CVCardiod()\n",
        "        self.conv2 = compnn.CVConv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
        "        self.fc1 = compnn.CVLinear(5 * 5 * 20, 50)\n",
        "        self.fc2 = compnn.CVLinear(50, 10)\n",
        "        self.smx = compnn.PhaseSoftMax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        mxpool1 = compnn.CVAdaptiveAvgPool2d((x.shape[2] // 2, x.shape[3] // 2))\n",
        "        x = mxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu1(x)\n",
        "        mxpool1 = compnn.CVAdaptiveAvgPool2d((x.shape[2] // 2, x.shape[3] // 2))\n",
        "        x = mxpool1(x)\n",
        "        x = x.view(-1, 5 * 5 * 20)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = x.abs()\n",
        "        out = self.smx(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "7xWkdTNoX4O8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    total_correct = 0\n",
        "    total_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = complextorch.CVTensor(data, i=torch.zeros_like(data)).to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # loss = compnn.CVCauchyError()\n",
        "        # loss = loss_fun(output, target)\n",
        "        # target_oh = to_categorical(target, 10)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_correct += torch.sum(pred == target.data).item()\n",
        "        total_loss += loss.item()\n",
        "        if batch_idx % 100 == 0 and batch_idx > 0:\n",
        "            print('Train Epoch: {:3} [{:6}/{:6} ({:3.0f}%)]\\tLoss: {:.6f}\\t Acc:{:.6f}'.format(\n",
        "                epoch,\n",
        "                batch_idx * len(data),\n",
        "                len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                total_loss / (batch_idx + 1),\n",
        "                total_correct/((batch_idx + 1) * batch_size)\n",
        "            )\n",
        "            )"
      ],
      "metadata": {
        "id": "ITKQoqoGX7yk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "model = ComplexNet().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "IRRcl5z7X_oc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(50)):\n",
        "    train(model, device, train_loader, optimizer, epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6F9QL4FYEdV",
        "outputId": "86bd406f-0f44-4e5c-bb25-5254561ab598"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:   0 [ 10000/ 50000 ( 20%)]\tLoss: 2.212387\t Acc:0.238713\n",
            "Train Epoch:   0 [ 20000/ 50000 ( 40%)]\tLoss: 2.175684\t Acc:0.277313\n",
            "Train Epoch:   0 [ 30000/ 50000 ( 60%)]\tLoss: 2.152604\t Acc:0.301163\n",
            "Train Epoch:   0 [ 40000/ 50000 ( 80%)]\tLoss: 2.131905\t Acc:0.323267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [00:18<15:21, 18.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:   1 [ 10000/ 50000 ( 20%)]\tLoss: 2.045575\t Acc:0.411782\n",
            "Train Epoch:   1 [ 20000/ 50000 ( 40%)]\tLoss: 2.031378\t Acc:0.427015\n",
            "Train Epoch:   1 [ 30000/ 50000 ( 60%)]\tLoss: 2.026704\t Acc:0.431429\n",
            "Train Epoch:   1 [ 40000/ 50000 ( 80%)]\tLoss: 2.022033\t Acc:0.436434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:35<14:09, 17.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:   2 [ 10000/ 50000 ( 20%)]\tLoss: 1.991332\t Acc:0.466931\n",
            "Train Epoch:   2 [ 20000/ 50000 ( 40%)]\tLoss: 1.980661\t Acc:0.478010\n",
            "Train Epoch:   2 [ 30000/ 50000 ( 60%)]\tLoss: 1.978275\t Acc:0.480963\n",
            "Train Epoch:   2 [ 40000/ 50000 ( 80%)]\tLoss: 1.972816\t Acc:0.486484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:52<13:22, 17.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:   3 [ 10000/ 50000 ( 20%)]\tLoss: 1.942325\t Acc:0.516931\n",
            "Train Epoch:   3 [ 20000/ 50000 ( 40%)]\tLoss: 1.942526\t Acc:0.516468\n",
            "Train Epoch:   3 [ 30000/ 50000 ( 60%)]\tLoss: 1.942325\t Acc:0.516512\n",
            "Train Epoch:   3 [ 40000/ 50000 ( 80%)]\tLoss: 1.941296\t Acc:0.517805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [01:08<12:56, 16.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:   4 [ 10000/ 50000 ( 20%)]\tLoss: 1.915305\t Acc:0.543366\n",
            "Train Epoch:   4 [ 20000/ 50000 ( 40%)]\tLoss: 1.913636\t Acc:0.546418\n",
            "Train Epoch:   4 [ 30000/ 50000 ( 60%)]\tLoss: 1.914636\t Acc:0.545249\n",
            "Train Epoch:   4 [ 40000/ 50000 ( 80%)]\tLoss: 1.915540\t Acc:0.544115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [01:25<12:37, 16.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:   5 [ 10000/ 50000 ( 20%)]\tLoss: 1.897276\t Acc:0.563069\n",
            "Train Epoch:   5 [ 20000/ 50000 ( 40%)]\tLoss: 1.897905\t Acc:0.562985\n",
            "Train Epoch:   5 [ 30000/ 50000 ( 60%)]\tLoss: 1.897103\t Acc:0.563256\n",
            "Train Epoch:   5 [ 40000/ 50000 ( 80%)]\tLoss: 1.898547\t Acc:0.561895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [01:41<12:12, 16.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:   6 [ 10000/ 50000 ( 20%)]\tLoss: 1.886038\t Acc:0.575248\n",
            "Train Epoch:   6 [ 20000/ 50000 ( 40%)]\tLoss: 1.884902\t Acc:0.575174\n",
            "Train Epoch:   6 [ 30000/ 50000 ( 60%)]\tLoss: 1.883417\t Acc:0.576146\n",
            "Train Epoch:   6 [ 40000/ 50000 ( 80%)]\tLoss: 1.881637\t Acc:0.578379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [01:58<11:57, 16.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:   7 [ 10000/ 50000 ( 20%)]\tLoss: 1.860686\t Acc:0.604257\n",
            "Train Epoch:   7 [ 20000/ 50000 ( 40%)]\tLoss: 1.867323\t Acc:0.595721\n",
            "Train Epoch:   7 [ 30000/ 50000 ( 60%)]\tLoss: 1.869558\t Acc:0.593289\n",
            "Train Epoch:   7 [ 40000/ 50000 ( 80%)]\tLoss: 1.868974\t Acc:0.593491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [02:14<11:38, 16.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:   8 [ 10000/ 50000 ( 20%)]\tLoss: 1.844911\t Acc:0.613861\n",
            "Train Epoch:   8 [ 20000/ 50000 ( 40%)]\tLoss: 1.853083\t Acc:0.607612\n",
            "Train Epoch:   8 [ 30000/ 50000 ( 60%)]\tLoss: 1.853219\t Acc:0.608007\n",
            "Train Epoch:   8 [ 40000/ 50000 ( 80%)]\tLoss: 1.853553\t Acc:0.607506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [02:31<11:19, 16.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:   9 [ 10000/ 50000 ( 20%)]\tLoss: 1.834103\t Acc:0.629703\n",
            "Train Epoch:   9 [ 20000/ 50000 ( 40%)]\tLoss: 1.841118\t Acc:0.621990\n",
            "Train Epoch:   9 [ 30000/ 50000 ( 60%)]\tLoss: 1.842398\t Acc:0.620864\n",
            "Train Epoch:   9 [ 40000/ 50000 ( 80%)]\tLoss: 1.843959\t Acc:0.618180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [02:48<11:06, 16.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  10 [ 10000/ 50000 ( 20%)]\tLoss: 1.825375\t Acc:0.635545\n",
            "Train Epoch:  10 [ 20000/ 50000 ( 40%)]\tLoss: 1.829151\t Acc:0.632090\n",
            "Train Epoch:  10 [ 30000/ 50000 ( 60%)]\tLoss: 1.831342\t Acc:0.629568\n",
            "Train Epoch:  10 [ 40000/ 50000 ( 80%)]\tLoss: 1.833206\t Acc:0.628279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [03:04<10:48, 16.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  11 [ 10000/ 50000 ( 20%)]\tLoss: 1.823287\t Acc:0.638218\n",
            "Train Epoch:  11 [ 20000/ 50000 ( 40%)]\tLoss: 1.826586\t Acc:0.634627\n",
            "Train Epoch:  11 [ 30000/ 50000 ( 60%)]\tLoss: 1.827819\t Acc:0.633588\n",
            "Train Epoch:  11 [ 40000/ 50000 ( 80%)]\tLoss: 1.826533\t Acc:0.634888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [03:21<10:36, 16.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  12 [ 10000/ 50000 ( 20%)]\tLoss: 1.803819\t Acc:0.660396\n",
            "Train Epoch:  12 [ 20000/ 50000 ( 40%)]\tLoss: 1.810254\t Acc:0.652886\n",
            "Train Epoch:  12 [ 30000/ 50000 ( 60%)]\tLoss: 1.813438\t Acc:0.648837\n",
            "Train Epoch:  12 [ 40000/ 50000 ( 80%)]\tLoss: 1.812824\t Acc:0.649601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [03:38<10:13, 16.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  13 [ 10000/ 50000 ( 20%)]\tLoss: 1.798895\t Acc:0.663465\n",
            "Train Epoch:  13 [ 20000/ 50000 ( 40%)]\tLoss: 1.799350\t Acc:0.663682\n",
            "Train Epoch:  13 [ 30000/ 50000 ( 60%)]\tLoss: 1.801209\t Acc:0.662159\n",
            "Train Epoch:  13 [ 40000/ 50000 ( 80%)]\tLoss: 1.803799\t Acc:0.659127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [03:54<09:54, 16.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  14 [ 10000/ 50000 ( 20%)]\tLoss: 1.797015\t Acc:0.667228\n",
            "Train Epoch:  14 [ 20000/ 50000 ( 40%)]\tLoss: 1.793678\t Acc:0.669801\n",
            "Train Epoch:  14 [ 30000/ 50000 ( 60%)]\tLoss: 1.796790\t Acc:0.665914\n",
            "Train Epoch:  14 [ 40000/ 50000 ( 80%)]\tLoss: 1.797938\t Acc:0.664713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [04:11<09:43, 16.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  15 [ 10000/ 50000 ( 20%)]\tLoss: 1.792013\t Acc:0.672376\n",
            "Train Epoch:  15 [ 20000/ 50000 ( 40%)]\tLoss: 1.788821\t Acc:0.674726\n",
            "Train Epoch:  15 [ 30000/ 50000 ( 60%)]\tLoss: 1.787893\t Acc:0.675515\n",
            "Train Epoch:  15 [ 40000/ 50000 ( 80%)]\tLoss: 1.789186\t Acc:0.674165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [04:27<09:24, 16.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  16 [ 10000/ 50000 ( 20%)]\tLoss: 1.776474\t Acc:0.685446\n",
            "Train Epoch:  16 [ 20000/ 50000 ( 40%)]\tLoss: 1.777635\t Acc:0.684577\n",
            "Train Epoch:  16 [ 30000/ 50000 ( 60%)]\tLoss: 1.778319\t Acc:0.684186\n",
            "Train Epoch:  16 [ 40000/ 50000 ( 80%)]\tLoss: 1.781237\t Acc:0.681322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [04:44<09:11, 16.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  17 [ 10000/ 50000 ( 20%)]\tLoss: 1.770687\t Acc:0.693069\n",
            "Train Epoch:  17 [ 20000/ 50000 ( 40%)]\tLoss: 1.773534\t Acc:0.690100\n",
            "Train Epoch:  17 [ 30000/ 50000 ( 60%)]\tLoss: 1.774666\t Acc:0.688804\n",
            "Train Epoch:  17 [ 40000/ 50000 ( 80%)]\tLoss: 1.776929\t Acc:0.686135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [05:01<08:50, 16.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  18 [ 10000/ 50000 ( 20%)]\tLoss: 1.764089\t Acc:0.698713\n",
            "Train Epoch:  18 [ 20000/ 50000 ( 40%)]\tLoss: 1.765709\t Acc:0.697562\n",
            "Train Epoch:  18 [ 30000/ 50000 ( 60%)]\tLoss: 1.765631\t Acc:0.697442\n",
            "Train Epoch:  18 [ 40000/ 50000 ( 80%)]\tLoss: 1.767240\t Acc:0.695536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [05:17<08:31, 16.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  19 [ 10000/ 50000 ( 20%)]\tLoss: 1.761108\t Acc:0.702376\n",
            "Train Epoch:  19 [ 20000/ 50000 ( 40%)]\tLoss: 1.755207\t Acc:0.707960\n",
            "Train Epoch:  19 [ 30000/ 50000 ( 60%)]\tLoss: 1.760637\t Acc:0.702226\n",
            "Train Epoch:  19 [ 40000/ 50000 ( 80%)]\tLoss: 1.762136\t Acc:0.700574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [05:34<08:19, 16.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  20 [ 10000/ 50000 ( 20%)]\tLoss: 1.750517\t Acc:0.711188\n",
            "Train Epoch:  20 [ 20000/ 50000 ( 40%)]\tLoss: 1.753681\t Acc:0.709851\n",
            "Train Epoch:  20 [ 30000/ 50000 ( 60%)]\tLoss: 1.754999\t Acc:0.708007\n",
            "Train Epoch:  20 [ 40000/ 50000 ( 80%)]\tLoss: 1.757063\t Acc:0.705985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [05:50<08:00, 16.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  21 [ 10000/ 50000 ( 20%)]\tLoss: 1.754718\t Acc:0.710198\n",
            "Train Epoch:  21 [ 20000/ 50000 ( 40%)]\tLoss: 1.746457\t Acc:0.718408\n",
            "Train Epoch:  21 [ 30000/ 50000 ( 60%)]\tLoss: 1.749104\t Acc:0.714518\n",
            "Train Epoch:  21 [ 40000/ 50000 ( 80%)]\tLoss: 1.751832\t Acc:0.711421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [06:07<07:45, 16.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  22 [ 10000/ 50000 ( 20%)]\tLoss: 1.742272\t Acc:0.719406\n",
            "Train Epoch:  22 [ 20000/ 50000 ( 40%)]\tLoss: 1.743735\t Acc:0.718507\n",
            "Train Epoch:  22 [ 30000/ 50000 ( 60%)]\tLoss: 1.746259\t Acc:0.715947\n",
            "Train Epoch:  22 [ 40000/ 50000 ( 80%)]\tLoss: 1.748736\t Acc:0.713466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [06:23<07:26, 16.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  23 [ 10000/ 50000 ( 20%)]\tLoss: 1.738299\t Acc:0.725743\n",
            "Train Epoch:  23 [ 20000/ 50000 ( 40%)]\tLoss: 1.733895\t Acc:0.730050\n",
            "Train Epoch:  23 [ 30000/ 50000 ( 60%)]\tLoss: 1.740804\t Acc:0.722757\n",
            "Train Epoch:  23 [ 40000/ 50000 ( 80%)]\tLoss: 1.742702\t Acc:0.721097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [06:40<07:07, 16.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  24 [ 10000/ 50000 ( 20%)]\tLoss: 1.737794\t Acc:0.725347\n",
            "Train Epoch:  24 [ 20000/ 50000 ( 40%)]\tLoss: 1.734946\t Acc:0.728159\n",
            "Train Epoch:  24 [ 30000/ 50000 ( 60%)]\tLoss: 1.738877\t Acc:0.724286\n",
            "Train Epoch:  24 [ 40000/ 50000 ( 80%)]\tLoss: 1.739393\t Acc:0.723491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [06:57<06:55, 16.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  25 [ 10000/ 50000 ( 20%)]\tLoss: 1.731377\t Acc:0.732772\n",
            "Train Epoch:  25 [ 20000/ 50000 ( 40%)]\tLoss: 1.732961\t Acc:0.730448\n",
            "Train Epoch:  25 [ 30000/ 50000 ( 60%)]\tLoss: 1.734693\t Acc:0.728771\n",
            "Train Epoch:  25 [ 40000/ 50000 ( 80%)]\tLoss: 1.735140\t Acc:0.728180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [07:13<06:37, 16.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  26 [ 10000/ 50000 ( 20%)]\tLoss: 1.724904\t Acc:0.738416\n",
            "Train Epoch:  26 [ 20000/ 50000 ( 40%)]\tLoss: 1.727669\t Acc:0.735124\n",
            "Train Epoch:  26 [ 30000/ 50000 ( 60%)]\tLoss: 1.730320\t Acc:0.732724\n",
            "Train Epoch:  26 [ 40000/ 50000 ( 80%)]\tLoss: 1.730489\t Acc:0.732693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [07:30<06:21, 16.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  27 [ 10000/ 50000 ( 20%)]\tLoss: 1.719349\t Acc:0.742871\n",
            "Train Epoch:  27 [ 20000/ 50000 ( 40%)]\tLoss: 1.722900\t Acc:0.739950\n",
            "Train Epoch:  27 [ 30000/ 50000 ( 60%)]\tLoss: 1.723724\t Acc:0.738970\n",
            "Train Epoch:  27 [ 40000/ 50000 ( 80%)]\tLoss: 1.725216\t Acc:0.737406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [07:46<06:05, 16.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  28 [ 10000/ 50000 ( 20%)]\tLoss: 1.721868\t Acc:0.741881\n",
            "Train Epoch:  28 [ 20000/ 50000 ( 40%)]\tLoss: 1.718640\t Acc:0.744378\n",
            "Train Epoch:  28 [ 30000/ 50000 ( 60%)]\tLoss: 1.720771\t Acc:0.742392\n",
            "Train Epoch:  28 [ 40000/ 50000 ( 80%)]\tLoss: 1.722452\t Acc:0.740574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [08:03<05:46, 16.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  29 [ 10000/ 50000 ( 20%)]\tLoss: 1.717099\t Acc:0.746832\n",
            "Train Epoch:  29 [ 20000/ 50000 ( 40%)]\tLoss: 1.716237\t Acc:0.747015\n",
            "Train Epoch:  29 [ 30000/ 50000 ( 60%)]\tLoss: 1.717457\t Acc:0.745316\n",
            "Train Epoch:  29 [ 40000/ 50000 ( 80%)]\tLoss: 1.718007\t Acc:0.744938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [08:20<05:32, 16.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  30 [ 10000/ 50000 ( 20%)]\tLoss: 1.714946\t Acc:0.747921\n",
            "Train Epoch:  30 [ 20000/ 50000 ( 40%)]\tLoss: 1.714531\t Acc:0.748408\n",
            "Train Epoch:  30 [ 30000/ 50000 ( 60%)]\tLoss: 1.717008\t Acc:0.745681\n",
            "Train Epoch:  30 [ 40000/ 50000 ( 80%)]\tLoss: 1.715439\t Acc:0.747656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [08:36<05:13, 16.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  31 [ 10000/ 50000 ( 20%)]\tLoss: 1.714702\t Acc:0.749307\n",
            "Train Epoch:  31 [ 20000/ 50000 ( 40%)]\tLoss: 1.711639\t Acc:0.752040\n",
            "Train Epoch:  31 [ 30000/ 50000 ( 60%)]\tLoss: 1.710589\t Acc:0.753322\n",
            "Train Epoch:  31 [ 40000/ 50000 ( 80%)]\tLoss: 1.714322\t Acc:0.749102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [08:52<04:56, 16.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  32 [ 10000/ 50000 ( 20%)]\tLoss: 1.707170\t Acc:0.756139\n",
            "Train Epoch:  32 [ 20000/ 50000 ( 40%)]\tLoss: 1.703637\t Acc:0.759502\n",
            "Train Epoch:  32 [ 30000/ 50000 ( 60%)]\tLoss: 1.706695\t Acc:0.755847\n",
            "Train Epoch:  32 [ 40000/ 50000 ( 80%)]\tLoss: 1.709329\t Acc:0.753117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [09:09<04:41, 16.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  33 [ 10000/ 50000 ( 20%)]\tLoss: 1.705813\t Acc:0.756238\n",
            "Train Epoch:  33 [ 20000/ 50000 ( 40%)]\tLoss: 1.707274\t Acc:0.755771\n",
            "Train Epoch:  33 [ 30000/ 50000 ( 60%)]\tLoss: 1.708632\t Acc:0.754286\n",
            "Train Epoch:  33 [ 40000/ 50000 ( 80%)]\tLoss: 1.709525\t Acc:0.753367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [09:25<04:24, 16.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  34 [ 10000/ 50000 ( 20%)]\tLoss: 1.699278\t Acc:0.764059\n",
            "Train Epoch:  34 [ 20000/ 50000 ( 40%)]\tLoss: 1.702171\t Acc:0.761244\n",
            "Train Epoch:  34 [ 30000/ 50000 ( 60%)]\tLoss: 1.703941\t Acc:0.759236\n",
            "Train Epoch:  34 [ 40000/ 50000 ( 80%)]\tLoss: 1.702567\t Acc:0.760449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [09:42<04:09, 16.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  35 [ 10000/ 50000 ( 20%)]\tLoss: 1.696117\t Acc:0.767228\n",
            "Train Epoch:  35 [ 20000/ 50000 ( 40%)]\tLoss: 1.695722\t Acc:0.767164\n",
            "Train Epoch:  35 [ 30000/ 50000 ( 60%)]\tLoss: 1.698042\t Acc:0.764751\n",
            "Train Epoch:  35 [ 40000/ 50000 ( 80%)]\tLoss: 1.700932\t Acc:0.761471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [09:58<03:51, 16.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  36 [ 10000/ 50000 ( 20%)]\tLoss: 1.691907\t Acc:0.770891\n",
            "Train Epoch:  36 [ 20000/ 50000 ( 40%)]\tLoss: 1.697747\t Acc:0.765075\n",
            "Train Epoch:  36 [ 30000/ 50000 ( 60%)]\tLoss: 1.698145\t Acc:0.764551\n",
            "Train Epoch:  36 [ 40000/ 50000 ( 80%)]\tLoss: 1.698705\t Acc:0.764090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [10:15<03:34, 16.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  37 [ 10000/ 50000 ( 20%)]\tLoss: 1.689989\t Acc:0.773267\n",
            "Train Epoch:  37 [ 20000/ 50000 ( 40%)]\tLoss: 1.692467\t Acc:0.770647\n",
            "Train Epoch:  37 [ 30000/ 50000 ( 60%)]\tLoss: 1.691453\t Acc:0.771429\n",
            "Train Epoch:  37 [ 40000/ 50000 ( 80%)]\tLoss: 1.694092\t Acc:0.768454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [10:32<03:19, 16.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  38 [ 10000/ 50000 ( 20%)]\tLoss: 1.694222\t Acc:0.767327\n",
            "Train Epoch:  38 [ 20000/ 50000 ( 40%)]\tLoss: 1.693773\t Acc:0.768408\n",
            "Train Epoch:  38 [ 30000/ 50000 ( 60%)]\tLoss: 1.693390\t Acc:0.769070\n",
            "Train Epoch:  38 [ 40000/ 50000 ( 80%)]\tLoss: 1.693167\t Acc:0.769252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [10:48<03:02, 16.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  39 [ 10000/ 50000 ( 20%)]\tLoss: 1.680717\t Acc:0.781881\n",
            "Train Epoch:  39 [ 20000/ 50000 ( 40%)]\tLoss: 1.683513\t Acc:0.779055\n",
            "Train Epoch:  39 [ 30000/ 50000 ( 60%)]\tLoss: 1.688347\t Acc:0.773920\n",
            "Train Epoch:  39 [ 40000/ 50000 ( 80%)]\tLoss: 1.689738\t Acc:0.772643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [11:05<02:47, 16.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  40 [ 10000/ 50000 ( 20%)]\tLoss: 1.683605\t Acc:0.778515\n",
            "Train Epoch:  40 [ 20000/ 50000 ( 40%)]\tLoss: 1.684319\t Acc:0.778507\n",
            "Train Epoch:  40 [ 30000/ 50000 ( 60%)]\tLoss: 1.685588\t Acc:0.777110\n",
            "Train Epoch:  40 [ 40000/ 50000 ( 80%)]\tLoss: 1.688227\t Acc:0.774264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [11:22<02:29, 16.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  41 [ 10000/ 50000 ( 20%)]\tLoss: 1.679165\t Acc:0.782871\n",
            "Train Epoch:  41 [ 20000/ 50000 ( 40%)]\tLoss: 1.683101\t Acc:0.779055\n",
            "Train Epoch:  41 [ 30000/ 50000 ( 60%)]\tLoss: 1.683206\t Acc:0.779236\n",
            "Train Epoch:  41 [ 40000/ 50000 ( 80%)]\tLoss: 1.684849\t Acc:0.777805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [11:38<02:11, 16.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  42 [ 10000/ 50000 ( 20%)]\tLoss: 1.682669\t Acc:0.779901\n",
            "Train Epoch:  42 [ 20000/ 50000 ( 40%)]\tLoss: 1.683780\t Acc:0.779254\n",
            "Train Epoch:  42 [ 30000/ 50000 ( 60%)]\tLoss: 1.683433\t Acc:0.779502\n",
            "Train Epoch:  42 [ 40000/ 50000 ( 80%)]\tLoss: 1.685075\t Acc:0.777855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [11:55<01:56, 16.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  43 [ 10000/ 50000 ( 20%)]\tLoss: 1.674380\t Acc:0.788515\n",
            "Train Epoch:  43 [ 20000/ 50000 ( 40%)]\tLoss: 1.676892\t Acc:0.785920\n",
            "Train Epoch:  43 [ 30000/ 50000 ( 60%)]\tLoss: 1.682219\t Acc:0.780299\n",
            "Train Epoch:  43 [ 40000/ 50000 ( 80%)]\tLoss: 1.684150\t Acc:0.778504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [12:11<01:39, 16.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  44 [ 10000/ 50000 ( 20%)]\tLoss: 1.678729\t Acc:0.783564\n",
            "Train Epoch:  44 [ 20000/ 50000 ( 40%)]\tLoss: 1.680254\t Acc:0.781841\n",
            "Train Epoch:  44 [ 30000/ 50000 ( 60%)]\tLoss: 1.682263\t Acc:0.780133\n",
            "Train Epoch:  44 [ 40000/ 50000 ( 80%)]\tLoss: 1.681709\t Acc:0.780698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [12:28<01:23, 16.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  45 [ 10000/ 50000 ( 20%)]\tLoss: 1.682635\t Acc:0.779703\n",
            "Train Epoch:  45 [ 20000/ 50000 ( 40%)]\tLoss: 1.678909\t Acc:0.783532\n",
            "Train Epoch:  45 [ 30000/ 50000 ( 60%)]\tLoss: 1.679363\t Acc:0.783389\n",
            "Train Epoch:  45 [ 40000/ 50000 ( 80%)]\tLoss: 1.680058\t Acc:0.782469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [12:45<01:06, 16.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  46 [ 10000/ 50000 ( 20%)]\tLoss: 1.673853\t Acc:0.788020\n",
            "Train Epoch:  46 [ 20000/ 50000 ( 40%)]\tLoss: 1.677800\t Acc:0.784677\n",
            "Train Epoch:  46 [ 30000/ 50000 ( 60%)]\tLoss: 1.677240\t Acc:0.785050\n",
            "Train Epoch:  46 [ 40000/ 50000 ( 80%)]\tLoss: 1.678900\t Acc:0.783566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [13:01<00:49, 16.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  47 [ 10000/ 50000 ( 20%)]\tLoss: 1.668382\t Acc:0.794653\n",
            "Train Epoch:  47 [ 20000/ 50000 ( 40%)]\tLoss: 1.672634\t Acc:0.790000\n",
            "Train Epoch:  47 [ 30000/ 50000 ( 60%)]\tLoss: 1.673288\t Acc:0.789169\n",
            "Train Epoch:  47 [ 40000/ 50000 ( 80%)]\tLoss: 1.673898\t Acc:0.788504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [13:18<00:33, 16.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  48 [ 10000/ 50000 ( 20%)]\tLoss: 1.664257\t Acc:0.798119\n",
            "Train Epoch:  48 [ 20000/ 50000 ( 40%)]\tLoss: 1.669792\t Acc:0.792189\n",
            "Train Epoch:  48 [ 30000/ 50000 ( 60%)]\tLoss: 1.670573\t Acc:0.791728\n",
            "Train Epoch:  48 [ 40000/ 50000 ( 80%)]\tLoss: 1.674323\t Acc:0.787955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [13:34<00:16, 16.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  49 [ 10000/ 50000 ( 20%)]\tLoss: 1.663043\t Acc:0.800396\n",
            "Train Epoch:  49 [ 20000/ 50000 ( 40%)]\tLoss: 1.665654\t Acc:0.797313\n",
            "Train Epoch:  49 [ 30000/ 50000 ( 60%)]\tLoss: 1.668057\t Acc:0.794352\n",
            "Train Epoch:  49 [ 40000/ 50000 ( 80%)]\tLoss: 1.668841\t Acc:0.793716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [13:51<00:00, 16.63s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "total_correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for batch_idx, (data, label) in enumerate(test_loader):\n",
        "\n",
        "        data, label = complextorch.CVTensor(data, i=torch.zeros_like(data)).to(device), label.to(device)\n",
        "\n",
        "        out = model(data)\n",
        "\n",
        "        _, pred = torch.max(out, 1)\n",
        "\n",
        "        total_correct += (label == pred).sum().item()\n",
        "\n",
        "    print(100 * total_correct/len(test_loader.dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZQdPSjrYJ90",
        "outputId": "a1782dde-958c-4ff6-f648-53e9601bd85f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "torch.Size([100, 3, 32, 32])\n",
            "62.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow implementation\n"
      ],
      "metadata": {
        "id": "vXMxvNmKYj6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install cvnn\n",
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N08waVKcYY2w",
        "outputId": "5eab7fda-6fc6-4b5b-a66f-3c715952d622"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cvnn\n",
            "  Downloading cvnn-2.0.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.10/dist-packages (from cvnn) (2.15.0)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.10/dist-packages (from cvnn) (0.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cvnn) (1.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from cvnn) (1.16.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cvnn) (24.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from cvnn) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from cvnn) (1.11.4)\n",
            "Collecting colorlog (from cvnn)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from cvnn) (3.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cvnn) (4.66.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0->cvnn) (2.15.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->cvnn) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->cvnn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->cvnn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->cvnn) (2024.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->cvnn) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->cvnn) (2.2.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->cvnn) (0.1.8)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->cvnn) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.0->cvnn) (3.2.2)\n",
            "Building wheels for collected packages: cvnn\n",
            "  Building wheel for cvnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cvnn: filename=cvnn-2.0-py2.py3-none-any.whl size=47610 sha256=1b3e5a5f71665987654d19d65f6339240322345d9fa530677ea79c858ec4a477\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/7c/d5/a4816f12ef5f955ed83cd22822d376f57aa0bc00b7ea2c4486\n",
            "Successfully built cvnn\n",
            "Installing collected packages: colorlog, cvnn\n",
            "Successfully installed colorlog-6.8.2 cvnn-2.0\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import cvnn.layers as complex_layers\n",
        "from cvnn.losses import ComplexAverageCrossEntropy\n",
        "from cvnn.metrics import ComplexCategoricalAccuracy\n",
        "import numpy as np\n",
        "from pdb import set_trace\n",
        "from keras.utils import to_categorical\n",
        "import warnings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDjoWJJNYseS",
        "outputId": "d3794934-0f97-4820-ed1a-dbf6d9f335ea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# for complex input"
      ],
      "metadata": {
        "id": "UitnmLco_OMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return torch.eye(num_classes)[y]"
      ],
      "metadata": {
        "id": "nH0e-MM-X2pJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images.astype(dtype=np.float32) / 255.0, test_images.astype(dtype=np.float32) / 255.0\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)"
      ],
      "metadata": {
        "id": "zWbkFZikYvhm"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def own_complex_fit(epochs=10):\n",
        "    tf.random.set_seed(1)\n",
        "    init = tf.keras.initializers.GlorotUniform(seed=117)\n",
        "    model = models.Sequential()\n",
        "    model.add(complex_layers.ComplexInput(input_shape=(32, 32, 3)))\n",
        "    model.add(complex_layers.ComplexConv2D(10, (5, 5), activation='complex_cardioid', input_shape=(32, 32, 3)))\n",
        "    model.add(complex_layers.ComplexMaxPooling2D((2, 2)))\n",
        "    model.add(complex_layers.ComplexBatchNormalization())\n",
        "    model.add(complex_layers.ComplexConv2D(20, (5, 5), activation='complex_cardioid', kernel_initializer=init))\n",
        "    model.add(complex_layers.ComplexMaxPooling2D((2, 2)))\n",
        "    # model.add(complex_layers.ComplexConv2D(64, (3, 3), activation='complex_cardioid', kernel_initializer=init))\n",
        "    model.add(complex_layers.ComplexFlatten())\n",
        "    model.add(complex_layers.ComplexDense(50, activation='complex_cardioid', kernel_initializer=init,))\n",
        "    model.add(complex_layers.ComplexDense(10, activation='cart_softmax'))\n",
        "    # model.summary()\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=ComplexAverageCrossEntropy(),\n",
        "                  metrics=ComplexCategoricalAccuracy())\n",
        "    weigths = model.get_weights()\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = model.compiled_loss(y_true=tf.convert_to_tensor(test_labels), y_pred=model(test_images))\n",
        "        gradients = tape.gradient(loss, model.trainable_weights)  # back-propagation\n",
        "    history = model.fit(train_images, train_labels, epochs=epochs, validation_data=(test_images, test_labels))\n",
        "    test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "    logs = {\n",
        "        'weights_at_init': weigths,\n",
        "        'loss': loss,\n",
        "        'gradients': gradients,\n",
        "        'weights_at_end': model.get_weights()\n",
        "    }\n",
        "    return history, logs"
      ],
      "metadata": {
        "id": "a-YgOKyTZmZd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "own, own_logs = own_complex_fit(epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07oK7rUwaCnT",
        "outputId": "7647e903-5f29-4d49-efcb-78cba607628f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: you are using a Tensorflow Initializer for complex numbers. Using mirror method.\n",
            "WARNING: you are using a Tensorflow Initializer for complex numbers. Using mirror method.\n",
            "Training was None and now is 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 36s 19ms/step - loss: 1.4583 - complex_categorical_accuracy: 0.4948 - val_loss: 1.5401 - val_complex_categorical_accuracy: 0.4858\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.0939 - complex_categorical_accuracy: 0.6282 - val_loss: 1.6242 - val_complex_categorical_accuracy: 0.5168\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.9700 - complex_categorical_accuracy: 0.6711 - val_loss: 0.9993 - val_complex_categorical_accuracy: 0.6577\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8860 - complex_categorical_accuracy: 0.7011 - val_loss: 1.2348 - val_complex_categorical_accuracy: 0.5938\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.8266 - complex_categorical_accuracy: 0.7220 - val_loss: 1.1968 - val_complex_categorical_accuracy: 0.6133\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.7821 - complex_categorical_accuracy: 0.7376 - val_loss: 1.8389 - val_complex_categorical_accuracy: 0.4952\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7410 - complex_categorical_accuracy: 0.7541 - val_loss: 1.1617 - val_complex_categorical_accuracy: 0.6313\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.7092 - complex_categorical_accuracy: 0.7636 - val_loss: 1.1528 - val_complex_categorical_accuracy: 0.6409\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.6792 - complex_categorical_accuracy: 0.7748 - val_loss: 1.0611 - val_complex_categorical_accuracy: 0.6661\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.6511 - complex_categorical_accuracy: 0.7855 - val_loss: 1.3285 - val_complex_categorical_accuracy: 0.6105\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 0.6283 - complex_categorical_accuracy: 0.7918 - val_loss: 0.9925 - val_complex_categorical_accuracy: 0.6890\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.6077 - complex_categorical_accuracy: 0.8003 - val_loss: 1.0182 - val_complex_categorical_accuracy: 0.6904\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.5880 - complex_categorical_accuracy: 0.8070 - val_loss: 1.0781 - val_complex_categorical_accuracy: 0.6775\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 0.5684 - complex_categorical_accuracy: 0.8141 - val_loss: 1.0064 - val_complex_categorical_accuracy: 0.6977\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.5515 - complex_categorical_accuracy: 0.8231 - val_loss: 1.0474 - val_complex_categorical_accuracy: 0.6942\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.5408 - complex_categorical_accuracy: 0.8247 - val_loss: 1.3286 - val_complex_categorical_accuracy: 0.6461\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.5226 - complex_categorical_accuracy: 0.8301 - val_loss: 1.0152 - val_complex_categorical_accuracy: 0.7037\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.5059 - complex_categorical_accuracy: 0.8366 - val_loss: 1.1454 - val_complex_categorical_accuracy: 0.6774\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.4932 - complex_categorical_accuracy: 0.8432 - val_loss: 1.0968 - val_complex_categorical_accuracy: 0.6914\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.4815 - complex_categorical_accuracy: 0.8462 - val_loss: 1.0499 - val_complex_categorical_accuracy: 0.7067\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.4707 - complex_categorical_accuracy: 0.8494 - val_loss: 1.1587 - val_complex_categorical_accuracy: 0.6855\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.4604 - complex_categorical_accuracy: 0.8549 - val_loss: 1.1767 - val_complex_categorical_accuracy: 0.6914\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.4460 - complex_categorical_accuracy: 0.8592 - val_loss: 1.1345 - val_complex_categorical_accuracy: 0.6953\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.4356 - complex_categorical_accuracy: 0.8620 - val_loss: 1.4346 - val_complex_categorical_accuracy: 0.6456\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 33s 21ms/step - loss: 0.4302 - complex_categorical_accuracy: 0.8646 - val_loss: 1.2547 - val_complex_categorical_accuracy: 0.6748\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.4171 - complex_categorical_accuracy: 0.8691 - val_loss: 1.1503 - val_complex_categorical_accuracy: 0.6944\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.4127 - complex_categorical_accuracy: 0.8705 - val_loss: 1.6176 - val_complex_categorical_accuracy: 0.6194\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.4026 - complex_categorical_accuracy: 0.8747 - val_loss: 1.4445 - val_complex_categorical_accuracy: 0.6553\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.3936 - complex_categorical_accuracy: 0.8768 - val_loss: 1.2422 - val_complex_categorical_accuracy: 0.6891\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.3865 - complex_categorical_accuracy: 0.8795 - val_loss: 1.2179 - val_complex_categorical_accuracy: 0.6924\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.3761 - complex_categorical_accuracy: 0.8840 - val_loss: 1.2521 - val_complex_categorical_accuracy: 0.6926\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.3711 - complex_categorical_accuracy: 0.8860 - val_loss: 1.2576 - val_complex_categorical_accuracy: 0.6932\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.3641 - complex_categorical_accuracy: 0.8865 - val_loss: 1.3437 - val_complex_categorical_accuracy: 0.6861\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.3558 - complex_categorical_accuracy: 0.8917 - val_loss: 1.3364 - val_complex_categorical_accuracy: 0.6877\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.3468 - complex_categorical_accuracy: 0.8944 - val_loss: 1.3318 - val_complex_categorical_accuracy: 0.6879\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.3444 - complex_categorical_accuracy: 0.8959 - val_loss: 1.4209 - val_complex_categorical_accuracy: 0.6773\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.3318 - complex_categorical_accuracy: 0.8989 - val_loss: 1.3480 - val_complex_categorical_accuracy: 0.6857\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.3307 - complex_categorical_accuracy: 0.8998 - val_loss: 1.6403 - val_complex_categorical_accuracy: 0.6381\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.3271 - complex_categorical_accuracy: 0.9002 - val_loss: 1.4778 - val_complex_categorical_accuracy: 0.6719\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.3172 - complex_categorical_accuracy: 0.9056 - val_loss: 1.4724 - val_complex_categorical_accuracy: 0.6799\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.3112 - complex_categorical_accuracy: 0.9058 - val_loss: 1.5271 - val_complex_categorical_accuracy: 0.6677\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.3099 - complex_categorical_accuracy: 0.9071 - val_loss: 1.4860 - val_complex_categorical_accuracy: 0.6806\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3032 - complex_categorical_accuracy: 0.9088 - val_loss: 1.4978 - val_complex_categorical_accuracy: 0.6820\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2947 - complex_categorical_accuracy: 0.9122 - val_loss: 1.5350 - val_complex_categorical_accuracy: 0.6716\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 32s 20ms/step - loss: 0.2930 - complex_categorical_accuracy: 0.9123 - val_loss: 1.5189 - val_complex_categorical_accuracy: 0.6832\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.2917 - complex_categorical_accuracy: 0.9129 - val_loss: 1.6350 - val_complex_categorical_accuracy: 0.6606\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.2798 - complex_categorical_accuracy: 0.9169 - val_loss: 1.5035 - val_complex_categorical_accuracy: 0.6873\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.2799 - complex_categorical_accuracy: 0.9177 - val_loss: 1.5185 - val_complex_categorical_accuracy: 0.6900\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.2775 - complex_categorical_accuracy: 0.9174 - val_loss: 1.6200 - val_complex_categorical_accuracy: 0.6772\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.2679 - complex_categorical_accuracy: 0.9204 - val_loss: 1.6524 - val_complex_categorical_accuracy: 0.6681\n",
            "313/313 - 3s - loss: 1.6524 - complex_categorical_accuracy: 0.6681 - 3s/epoch - 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# for real input"
      ],
      "metadata": {
        "id": "6ZG-TY7A_a6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images.astype(dtype=np.float32) / 255.0, test_images.astype(dtype=np.float32) / 255.0"
      ],
      "metadata": {
        "id": "nGr6W6KI_KXd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def keras_fit(epochs=10, use_bias=True):\n",
        "    tf.random.set_seed(1)\n",
        "    init = tf.keras.initializers.GlorotUniform(seed=117)\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(10, (5, 5), activation='relu', input_shape=(32, 32, 3), kernel_initializer=init,\n",
        "                            use_bias=use_bias))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(20, (5, 5), activation='relu', kernel_initializer=init, use_bias=use_bias))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(50, activation='relu', kernel_initializer=init, use_bias=use_bias))\n",
        "    model.add(layers.Dense(10, kernel_initializer=init, use_bias=use_bias, activation='softmax'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "    weigths = model.get_weights()\n",
        "    with tf.GradientTape() as tape:\n",
        "        # for elem, label in iter(ds_train):\n",
        "        loss = model.compiled_loss(y_true=tf.convert_to_tensor(test_labels), y_pred=model(test_images))\n",
        "        gradients = tape.gradient(loss, model.trainable_weights)  # back-propagation\n",
        "    history = model.fit(train_images, train_labels, epochs=epochs, validation_data=(test_images, test_labels))\n",
        "    test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "    logs = {\n",
        "        'weights_at_init': weigths,\n",
        "        'loss': loss,\n",
        "        'gradients': gradients,\n",
        "        'weights_at_end': model.get_weights()\n",
        "    }\n",
        "    return history, logs"
      ],
      "metadata": {
        "id": "OUllmlSmYxXY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras, keras_logs = keras_fit(epochs=50, use_bias=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcliH0BMaCAf",
        "outputId": "64133773-d525-4d03-c787-5806755554b9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5391 - accuracy: 0.4413 - val_loss: 1.4017 - val_accuracy: 0.4921\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2555 - accuracy: 0.5526 - val_loss: 1.2401 - val_accuracy: 0.5517\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1477 - accuracy: 0.5912 - val_loss: 1.1929 - val_accuracy: 0.5829\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0790 - accuracy: 0.6168 - val_loss: 1.2815 - val_accuracy: 0.5535\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.0288 - accuracy: 0.6376 - val_loss: 1.2301 - val_accuracy: 0.5786\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9848 - accuracy: 0.6536 - val_loss: 1.0807 - val_accuracy: 0.6170\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.9534 - accuracy: 0.6631 - val_loss: 1.0870 - val_accuracy: 0.6254\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9237 - accuracy: 0.6747 - val_loss: 1.0777 - val_accuracy: 0.6243\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8998 - accuracy: 0.6815 - val_loss: 1.0741 - val_accuracy: 0.6320\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8779 - accuracy: 0.6910 - val_loss: 1.1030 - val_accuracy: 0.6253\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8532 - accuracy: 0.6978 - val_loss: 1.0482 - val_accuracy: 0.6448\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8412 - accuracy: 0.7029 - val_loss: 1.0476 - val_accuracy: 0.6444\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8212 - accuracy: 0.7104 - val_loss: 1.1345 - val_accuracy: 0.6211\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8056 - accuracy: 0.7146 - val_loss: 1.0936 - val_accuracy: 0.6352\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7919 - accuracy: 0.7191 - val_loss: 1.0727 - val_accuracy: 0.6388\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7828 - accuracy: 0.7231 - val_loss: 1.1375 - val_accuracy: 0.6189\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7664 - accuracy: 0.7290 - val_loss: 1.0762 - val_accuracy: 0.6451\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7567 - accuracy: 0.7327 - val_loss: 1.0936 - val_accuracy: 0.6386\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7441 - accuracy: 0.7355 - val_loss: 1.0704 - val_accuracy: 0.6440\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7351 - accuracy: 0.7397 - val_loss: 1.1176 - val_accuracy: 0.6352\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7228 - accuracy: 0.7433 - val_loss: 1.1239 - val_accuracy: 0.6417\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7153 - accuracy: 0.7453 - val_loss: 1.2014 - val_accuracy: 0.6185\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7063 - accuracy: 0.7487 - val_loss: 1.1730 - val_accuracy: 0.6304\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7014 - accuracy: 0.7516 - val_loss: 1.1038 - val_accuracy: 0.6412\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6885 - accuracy: 0.7546 - val_loss: 1.3017 - val_accuracy: 0.5941\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6813 - accuracy: 0.7581 - val_loss: 1.1703 - val_accuracy: 0.6272\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6755 - accuracy: 0.7581 - val_loss: 1.1724 - val_accuracy: 0.6349\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6678 - accuracy: 0.7623 - val_loss: 1.1643 - val_accuracy: 0.6373\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6614 - accuracy: 0.7640 - val_loss: 1.1996 - val_accuracy: 0.6252\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6544 - accuracy: 0.7674 - val_loss: 1.1657 - val_accuracy: 0.6410\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6462 - accuracy: 0.7700 - val_loss: 1.2173 - val_accuracy: 0.6257\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6463 - accuracy: 0.7708 - val_loss: 1.2597 - val_accuracy: 0.6109\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6367 - accuracy: 0.7726 - val_loss: 1.2158 - val_accuracy: 0.6335\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6335 - accuracy: 0.7751 - val_loss: 1.2435 - val_accuracy: 0.6313\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6266 - accuracy: 0.7761 - val_loss: 1.2665 - val_accuracy: 0.6213\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6263 - accuracy: 0.7766 - val_loss: 1.2273 - val_accuracy: 0.6285\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6190 - accuracy: 0.7780 - val_loss: 1.2723 - val_accuracy: 0.6244\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6162 - accuracy: 0.7788 - val_loss: 1.2179 - val_accuracy: 0.6341\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6109 - accuracy: 0.7812 - val_loss: 1.2344 - val_accuracy: 0.6335\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6043 - accuracy: 0.7826 - val_loss: 1.2714 - val_accuracy: 0.6272\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6004 - accuracy: 0.7853 - val_loss: 1.2518 - val_accuracy: 0.6270\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5970 - accuracy: 0.7858 - val_loss: 1.2788 - val_accuracy: 0.6296\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.5896 - accuracy: 0.7889 - val_loss: 1.2788 - val_accuracy: 0.6294\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5904 - accuracy: 0.7886 - val_loss: 1.2719 - val_accuracy: 0.6245\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5860 - accuracy: 0.7897 - val_loss: 1.2971 - val_accuracy: 0.6233\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5828 - accuracy: 0.7919 - val_loss: 1.3148 - val_accuracy: 0.6288\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5806 - accuracy: 0.7924 - val_loss: 1.3317 - val_accuracy: 0.6220\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.5749 - accuracy: 0.7943 - val_loss: 1.3595 - val_accuracy: 0.6175\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5733 - accuracy: 0.7946 - val_loss: 1.3622 - val_accuracy: 0.6160\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5691 - accuracy: 0.7965 - val_loss: 1.3491 - val_accuracy: 0.6217\n",
            "313/313 - 1s - loss: 1.3491 - accuracy: 0.6217 - 1s/epoch - 3ms/step\n"
          ]
        }
      ]
    }
  ]
}